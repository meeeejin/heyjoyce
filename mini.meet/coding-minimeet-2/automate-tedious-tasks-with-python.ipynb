{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 뉴스 기사 크롤링\n",
    "# 크롤링하기 위한 모듈 import\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL에 접근하기 위한 모듈 import\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 뉴스 검색할 키워드 입력\n",
    "searchKeyword = \"xxx\"\n",
    "\n",
    "# 뉴스 검색 결과를 가진 base URL\n",
    "baseURL = 'https://search.naver.com/search.naver?where=news&ie=utf8&sm=nws_hty&query={}'.format(searchKeyword)\n",
    "\n",
    "# 해당 URL로 이동해서 HTML 내용 스크래핑\n",
    "req = requests.get(baseURL)\n",
    " \n",
    "if req.ok:\n",
    "    html = req.text\n",
    "    soup = BeautifulSoup(html,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 결과로 나온 뉴스의 URL을 담을 리스트\n",
    "newsURLs = []\n",
    "\n",
    "# TODO: 스크래핑했던 HTML에서 URL만 추출 \n",
    "urlList = soup.select('xxx')\n",
    "\n",
    "# 네이버 뉴스에 해당하는 최종 URL 추출해서 뉴스 URL 리스트에 저장\n",
    "for url in urlList:\n",
    "    newsURL = url.get('href')\n",
    "    if newsURL.startswith(\"https://news.naver.com\"): \n",
    "        newsURLs.append(newsURL)\n",
    "        \n",
    "# 추출한 뉴스 URL 리스트 출력\n",
    "print(newsURLs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 뉴스 기사의 정보를 저장할 리스트\n",
    "newsFinalInfo = []\n",
    "\n",
    "# 각 뉴스 기사에서 날짜, 언론사, 뉴스 제목, 기사 내용 수집\n",
    "for newsURL in newsURLs:\n",
    "    # 각 기사의 디테일한 내용을 담을 리스트\n",
    "    newsDetails = []\n",
    "    \n",
    "    # 해당 URL로 이동해서 해당 기사의 HTML 내용 스크래핑\n",
    "    req = requests.get(newsURL)\n",
    "\n",
    "    if req.ok:\n",
    "        html = req.text\n",
    "        soup = BeautifulSoup(html,'html.parser')\n",
    "    \n",
    "    # 기사 날짜 추출\n",
    "    try:\n",
    "        time = soup.select('.t11')[0].text\n",
    "    except IndexError: \n",
    "        continue\n",
    "    newsDetails.append(time)\n",
    "    \n",
    "    # 언론사 추출\n",
    "    press = soup.select('.article_header > div > a > img')[0].get('title')\n",
    "    newsDetails.append(press)\n",
    "    \n",
    "    # TODO: 기사 제목 추출\n",
    "    title = soup.select('xxx')[0].text\n",
    "    newsDetails.append(title)\n",
    "    \n",
    "    # 기사 내용 추출\n",
    "    fullArticle = soup.select('#articleBodyContents')[0].get_text().replace('\\n', \" \")\n",
    "    parsedArticle = fullArticle.replace(\"// flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}\", \"\")\n",
    "    newsDetails.append(parsedArticle.strip())\n",
    "    \n",
    "    # 기사 URL을 마지막 원소로 저장\n",
    "    newsDetails.append(newsURL)\n",
    "    \n",
    "    # 위의 4가지 정보를 모아서 하나의 리스트로 만든 뒤, 최종 정보로 저장\n",
    "    newsFinalInfo.append(newsDetails)\n",
    "\n",
    "print(newsFinalInfo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 크롤링한 뉴스 기사 내용들을 엑셀로 저장하기\n",
    "# 데이터를 엑셀로 저장하고 조작하기 위한 Pandas 모듈 import\n",
    "import pandas as pd\n",
    "\n",
    "# 텍스트가 잘리는 현상 방지\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "# 위에서 수집한 뉴스 정보를 행렬 형태로 변환\n",
    "data = pd.DataFrame(newsFinalInfo) \n",
    "data.columns = ['날짜', '언론사', '제목', '내용', 'URL']\n",
    "\n",
    "# 상위 n행 출력\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XlsxWriter 엔진을 사용해 엑셀 writer를 만들고, 엑셀 파일에 쓸 준비\n",
    "writer = pd.ExcelWriter('news.xlsx', engine='xlsxwriter')\n",
    " \n",
    "# 행렬 데이터를 엑셀 파일에 쓰기\n",
    "data.to_excel(writer, sheet_name='Sheet1')\n",
    "\n",
    "# 엑셀 writer를 닫아줌으로써 엑셀 쓰기 작업 종료\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 위에서 만든 dataframe 및 엑셀 파일을 이메일로 보내기\n",
    "# 이메일을 보내는 데에 필요한 library import\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.base import MIMEBase\n",
    "from email import encoders\n",
    "\n",
    "# TODO: 발신자 Gmail 주소/password 및 수신자 Gmail 주소 입력\n",
    "sender = 'xxx@gmail.com'\n",
    "password = 'xxx'\n",
    "recipients = ['xxx@gmail.com']\n",
    "\n",
    "# 메일 제목 입력\n",
    "subject = searchKeyword + ' 관련 뉴스 크롤링 결과 공유 드립니다.' \n",
    "\n",
    "# 위의 메일 정보 저장\n",
    "msg = MIMEMultipart()\n",
    "msg['From'] = sender\n",
    "msg['To'] = \", \".join(recipients)\n",
    "msg['Subject'] = subject\n",
    "\n",
    "# TODO: 본문 텍스트 내용 입력\n",
    "body = \"\"\"\n",
    "안녕하세요. xxx의 xxx입니다.\n",
    "\n",
    "뉴스 크롤링 결과 아래 공유 드립니다.\n",
    "엑셀 파일도 따로 첨부했으니 확인 부탁드립니다.\n",
    "\n",
    "감사합니다.\n",
    "\n",
    "\"\"\"\n",
    "msg.attach(MIMEText(body, 'plain'))\n",
    "\n",
    "# 위의 뉴스 결과를 HTML 표 형식으로 첨부\n",
    "html = data.to_html()\n",
    "msg.attach(MIMEText(html, 'html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첨부파일 경로 및 이름 지정하기\n",
    "fileName = 'news.xlsx'  \n",
    "attachment = open(fileName, 'rb')\n",
    "\n",
    "# 첨부파일 첨부\n",
    "part = MIMEBase('application','octet-stream')\n",
    "part.set_payload((attachment).read())\n",
    "encoders.encode_base64(part)\n",
    "part.add_header('Content-Disposition', \"attachment; filename= \" + fileName)\n",
    "msg.attach(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이메일 전송 서버 준비\n",
    "server = smtplib.SMTP('smtp.gmail.com',587)\n",
    "server.starttls()\n",
    "\n",
    "# 로그인 및 이메일 전송\n",
    "server.login(sender, password)\n",
    "server.sendmail(sender, recipient, msg.as_string())\n",
    "\n",
    "# 이메일 전송 서버 종료\n",
    "server.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 엑셀 파일 읽어와서 그 내용을 이메일로 보내기\n",
    "# 엑셀 파일 읽어오기\n",
    "readData = pd.read_excel('example.xlsx')\n",
    "\n",
    "# 엑셀 파일 내용을 Data frame으로 저장\n",
    "data = pd.DataFrame(readData)\n",
    "\n",
    "# 읽어온 데이터 확인\n",
    "print(data)\n",
    "\n",
    "# 첫번째 열만 추출해서 다시 dataframe 형태로 저장\n",
    "data = data[data.columns[0]].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫번째 열 내용을 이메일로 전송\n",
    "# 위의 메일 정보 다시 저장\n",
    "msg = MIMEMultipart()\n",
    "msg['From'] = sender\n",
    "msg['To'] = \", \".join(recipients)\n",
    "\n",
    "# 메일 제목 입력\n",
    "subject = '카페 메뉴 공유 드립니다.' \n",
    "msg['Subject'] = subject\n",
    "\n",
    "# TODO: 본문 텍스트 내용 입력\n",
    "body = \"\"\"\n",
    "안녕하세요. xxx의 xxx입니다.\n",
    "\n",
    "저희 카페에서 판매하는 음료 종류는 아래와 같습니다.\n",
    "확인 부탁드립니다.\n",
    "\n",
    "감사합니다.\n",
    "\n",
    "\"\"\"\n",
    "msg.attach(MIMEText(body, 'plain'))\n",
    "\n",
    "# 위의 뉴스 결과를 HTML 표 형식으로 첨부\n",
    "html = data.to_html()\n",
    "msg.attach(MIMEText(html, 'html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이메일 전송 서버 준비\n",
    "server = smtplib.SMTP('smtp.gmail.com',587)\n",
    "server.starttls()\n",
    "\n",
    "# 로그인 및 이메일 전송\n",
    "server.login(sender, password)\n",
    "server.sendmail(sender, recipient, msg.as_string())\n",
    "\n",
    "# 이메일 전송 서버 종료\n",
    "server.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
